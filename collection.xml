<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Choi, Youngduck</author><author>Chiu, Chill Yi-I</author><author>Sontag, David</author></authors></contributors><titles><title>Learning Low-Dimensional Representations of Medical Concepts</title><secondary-title>AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science</secondary-title></titles><periodical><full-title>AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science</full-title></periodical><pages>41-50</pages><volume>2016</volume><keywords/><dates><year>2016</year></dates><publisher>American Medical Informatics Association</publisher><language>eng</language><urls><web-urls><url>https://www.ncbi.nlm.nih.gov/pubmed/27570647</url><url>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001761/</url></web-urls></urls><abstract>We show how to learn low-dimensional representations (embeddings) of a wide range of concepts in medicine, including diseases (e.g., ICD9 codes), medications, procedures, and laboratory tests. We expect that these embeddings will be useful across medical informatics for tasks such as cohort selection and patient summarization. These embeddings are learned using a technique called neural language modeling from the natural language processing community. However, rather than learning the embeddings solely from text, we show how to learn the embeddings from claims data, which is widely available both to providers and to payers. We also show that with a simple algorithmic adjustment, it is possible to learn medical concept embeddings in a privacy preserving manner from co-occurrence counts derived from clinical narratives. Finally, we establish a methodological framework, arising from standard medical ontologies such as UMLS, NDF-RT, and CCS, to further investigate the embeddings and precisely characterize their quantitative properties.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Choi, Edward</author><author>Bahadori, Mohammad Taha</author><author>Schuetz, Andy</author><author>Stewart, Walter F</author><author>Conference, Jimeng Sun B T - Proceedings of the 1st Machine Learning for Healthcare</author></authors><secondary-authors><author>Doshi-Velez, Finale</author><author>Fackler, Jim</author><author>Kale, David</author><author>Wallace, Byron</author><author>Wiens, Jenna</author></secondary-authors></contributors><titles><title>Doctor AI: Predicting Clinical Events via Recurrent Neural Networks</title><secondary-title>Proceedings of the 1st Machine Learning for Healthcare Conference</secondary-title></titles><periodical><full-title>Proceedings of the 1st Machine Learning for Healthcare Conference</full-title></periodical><pages>301-318</pages><keywords/><dates><year>2016</year></dates><publisher>PMLR</publisher><urls><web-urls><url>http://proceedings.mlr.press/v56/Choi16.pdf</url><url>http://proceedings.mlr.press/v56/Choi16.html</url></web-urls></urls><abstract>Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients and 2,128 physicians over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79% recall@30, significantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Miotto, Riccardo</author><author>Li, Li</author><author>Kidd, Brian A</author><author>Dudley, Joel T</author></authors></contributors><titles><title>Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records</title><secondary-title>Scientific Reports</secondary-title></titles><periodical><full-title>Scientific Reports</full-title></periodical><pages>26094</pages><volume>6</volume><keywords/><dates><year>2016</year></dates><publisher>The Author(s)</publisher><urls><web-urls><url>https://doi.org/10.1038/srep26094</url><url>http://10.0.4.14/srep26094</url><url>https://www.nature.com/articles/srep26094#supplementary-information</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Lipton, Zachary C.</author><author>Kale, David C.</author><author>Elkan, Charles</author><author>Wetzel, Randall</author></authors></contributors><titles><title>Learning to diagnose with LSTM recurrent neural networks</title><secondary-title>International Conference on Learning Representations (ICLR) 2016</secondary-title></titles><periodical><full-title>International Conference on Learning Representations (ICLR) 2016</full-title></periodical><pages>1-18</pages><keywords/><dates><year>2016</year></dates><urls/></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Choi, Edward</author><author>Bahadori, Mohammad Taha</author><author>Searles, Elizabeth</author><author>Coffey, Catherine</author><author>Thompson, Michael</author><author>Bost, James</author><author>Tejedor-Sojo, Javier</author><author>Sun, Jimeng</author></authors></contributors><titles><title>Multi-layer Representation Learning for Medical Concepts</title><secondary-title>Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</secondary-title></titles><periodical><full-title>Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</full-title></periodical><pages>1495-1504</pages><keywords><keyword>medical concepts</keyword><keyword>neural networks</keyword><keyword>representation learning</keyword><keyword>healthcare analytics</keyword></keywords><dates><year>2016</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-4232-2</isbn><electronic-resource-num>10.1145/2939672.2939823</electronic-resource-num><urls><web-urls><url>http://doi.acm.org/10.1145/2939672.2939823</url></web-urls></urls><abstract>Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Choi, Edward</author><author>Schuetz, Andy</author><author>Stewart, Walter F</author><author>Sun, Jimeng</author></authors></contributors><titles><title>Using recurrent neural network models for early detection of heart failure onset</title><secondary-title>Journal of the American Medical Informatics Association : JAMIA</secondary-title></titles><periodical><full-title>Journal of the American Medical Informatics Association : JAMIA</full-title></periodical><pages>361-370</pages><volume>24</volume><issue>2</issue><keywords><keyword>*Electronic Health Records</keyword><keyword>*Machine Learning</keyword><keyword>*Neural Networks (Computer)</keyword><keyword>*deep learning</keyword><keyword>*electronic health records</keyword><keyword>*heart failure prediction</keyword><keyword>*patient progression model</keyword><keyword>*recurrent neural network</keyword><keyword>Area Under Curve</keyword><keyword>Early Diagnosis</keyword><keyword>Heart Failure/*diagnosis</keyword><keyword>Humans</keyword><keyword>Logistic Models</keyword><keyword>Support Vector Machine</keyword></keywords><dates><year>2017</year></dates><publisher>Oxford University Press</publisher><electronic-resource-num>10.1093/jamia/ocw112</electronic-resource-num><language>eng</language><urls><web-urls><url>https://www.ncbi.nlm.nih.gov/pubmed/27521897</url><url>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5391725/</url></web-urls></urls><abstract>OBJECTIVE: We explored whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would improve model performance in predicting initial diagnosis of heart failure (HF) compared to conventional methods that ignore temporality. MATERIALS AND METHODS: Data were from a health system's EHR on 3884 incident HF cases and 28 903 controls, identified as primary care patients, between May 16, 2000, and May 23, 2013. Recurrent neural network (RNN) models using gated recurrent units (GRUs) were adapted to detect relations among time-stamped events (eg, disease diagnosis, medication orders, procedure orders, etc.) with a 12- to 18-month observation window of cases and controls. Model performance metrics were compared to regularized logistic regression, neural network, support vector machine, and K-nearest neighbor classifier approaches. RESULTS: Using a 12-month observation window, the area under the curve (AUC) for the RNN model was 0.777, compared to AUCs for logistic regression (0.747), multilayer perceptron (MLP) with 1 hidden layer (0.765), support vector machine (SVM) (0.743), and K-nearest neighbor (KNN) (0.730). When using an 18-month observation window, the AUC for the RNN model increased to 0.883 and was significantly higher than the 0.834 AUC for the best of the baseline methods (MLP). CONCLUSION: Deep learning models adapted to leverage temporal relations appear to improve performance of models for detection of incident heart failure with a short observation window of 12-18 months.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cai, Xiongcai</author><author>Perez-Concha, Oscar</author><author>Coiera, Enrico</author><author>Martin-Sanchez, Fernando</author><author>Day, Richard</author><author>Roffe, David</author><author>Gallego, Blanca</author></authors></contributors><titles><title>Real-time prediction of mortality, readmission, and length of stay using electronic health record data</title><secondary-title>Journal of the American Medical Informatics Association</secondary-title></titles><periodical><full-title>Journal of the American Medical Informatics Association</full-title></periodical><pages>553-561</pages><volume>23</volume><issue>3</issue><keywords/><dates><year>2016</year></dates><electronic-resource-num>10.1093/jamia/ocv110</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1093/jamia/ocv110</url></web-urls></urls><abstract>Objective To develop a predictive model for real-time predictions of length of stay, mortality, and readmission for hospitalized patients using electronic health records (EHRs).Materials and Methods A Bayesian Network model was built to estimate the probability of a hospitalized patient being “at home,” in the hospital, or dead for each of the next 7 days. The network utilizes patient-specific administrative and laboratory data and is updated each time a new pathology test result becomes available. Electronic health records from 32 634 patients admitted to a Sydney metropolitan hospital via the emergency department from July 2008 through December 2011 were used. The model was tested on 2011 data and trained on the data of earlier years.Results The model achieved an average daily accuracy of 80\\% and area under the receiving operating characteristic curve (AUROC) of 0.82. The model’s predictive ability was highest within 24 hours from prediction (AUROC = 0.83) and decreased slightly with time. Death was the most predictable outcome with a daily average accuracy of 93\\% and AUROC of 0.84.Discussion We developed the first non–disease-specific model that simultaneously predicts remaining days of hospitalization, death, and readmission as part of the same outcome. By providing a future daily probability for each outcome class, we enable the visualization of future patient trajectories. Among these, it is possible to identify trajectories indicating expected discharge, expected continuing hospitalization, expected death, and possible readmission.Conclusions Bayesian Networks can model EHRs to provide real-time forecasts for patient outcomes, which provide richer information than traditional independent point predictions of length of stay, death, or readmission, and can thus better support decision making.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bandara, Kasun</author><author>Bergmeir, Christoph</author><author>Smyl, Slawek</author></authors></contributors><titles><title>Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach</title><secondary-title>arXiv preprint arXiv:1710.03222</secondary-title></titles><periodical><full-title>arXiv preprint arXiv:1710.03222</full-title></periodical><keywords/><dates><year>2017</year></dates><urls><pdf-urls><url>internal-pdf://Bandara, Bergmeir, Smyl - 2017 - Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series A.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1710.03222</url></web-urls></urls><abstract>With the advent of Big Data, nowadays in many applications databases containing large quantities of similar time series are available. Forecasting time series in these domains with traditional univariate forecasting procedures leaves great potentials for producing accurate forecasts untapped. Recurrent neural networks (RNNs), and in particular Long Short-Term Memory (LSTM) networks, have proven recently that they are able to outperform state-of-the-art univariate time series forecasting methods in this context when trained across all available time series. However, if the time series database is heterogeneous, accuracy may degenerate, so that on the way towards fully automatic forecasting methods in this space, a notion of similarity between the time series needs to be built into the methods. To this end, we present a prediction model that can be used with different types of RNN models on subgroups of similar time series, which are identified by time series clustering techniques. We assess our proposed methodology using LSTM networks, a widely popular RNN variant. Our method achieves competitive results on benchmarking datasets under competition evaluation procedures. In particular, in terms of mean sMAPE accuracy, it consistently outperforms the baseline LSTM model and outperforms all other methods on the CIF2016 forecasting competition dataset.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dubois, Sebastien</author><author>Romano, Nathanael</author><author>Kale, David C.</author><author>Shah, Nigam</author><author>Jung, Kenneth</author></authors></contributors><titles><title>Effective Representations of Clinical Notes</title><secondary-title>arXiv preprint arXiv:1705.07025</secondary-title></titles><periodical><full-title>arXiv preprint arXiv:1705.07025</full-title></periodical><keywords/><dates><year>2017</year></dates><urls><pdf-urls><url>internal-pdf://Dubois et al. - 2017 - Effective Representations of Clinical Notes(2).pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1705.07025</url></web-urls></urls><abstract>Clinical notes are a rich source of information about patient state. However, using them to predict clinical events with machine learning models is challenging. They are very high dimensional, sparse and have complex structure. Furthermore, training data is often scarce because it is expensive to obtain reliable labels for many clinical events. These difficulties have traditionally been addressed by manual feature engineering encoding task specific domain knowledge. We explored the use of neural networks and transfer learning to learn representations of clinical notes that are useful for predicting future clinical events of interest, such as all causes mortality, inpatient admissions, and emergency room visits. Our data comprised 2.7 million notes and 115 thousand patients at Stanford Hospital. We used the learned representations, along with commonly used bag of words and topic model representations, as features for predictive models of clinical events. We evaluated the effectiveness of these representations with respect to the performance of the models trained on small datasets. Models using the neural network derived representations performed significantly better than models using the baseline representations with small ($N &lt; 1000$) training datasets. The learned representations offer significant performance gains over commonly used baseline representations for a range of predictive modeling tasks and cohort sizes, offering an effective alternative to task specific feature engineering when plentiful labeled training data is not available.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rajkomar, Alvin</author><author>Oren, Eyal</author><author>Chen, Kai</author><author>Dai, Andrew M</author><author>Hajaj, Nissan</author><author>Hardt, Michaela</author><author>Liu, Peter J</author><author>Liu, Xiaobing</author><author>Marcus, Jake</author><author>Sun, Mimi</author><author>Sundberg, Patrik</author><author>Yee, Hector</author><author>Zhang, Kun</author><author>Zhang, Yi</author><author>Flores, Gerardo</author><author>Duggan, Gavin E</author><author>Irvine, Jamie</author><author>Le, Quoc</author><author>Litsch, Kurt</author><author>Mossin, Alexander</author><author>Tansuwan, Justin</author><author>Wang, De</author><author>Wexler, James</author><author>Wilson, Jimbo</author><author>Ludwig, Dana</author><author>Volchenboum, Samuel L</author><author>Chou, Katherine</author><author>Pearson, Michael</author><author>Madabushi, Srinivasan</author><author>Shah, Nigam H</author><author>Butte, Atul J</author><author>Howell, Michael D</author><author>Cui, Claire</author><author>Corrado, Greg S</author><author>Dean, Jeffrey</author></authors></contributors><titles><title>Scalable and accurate deep learning with electronic health records</title><secondary-title>npj Digital Medicine</secondary-title></titles><periodical><full-title>npj Digital Medicine</full-title></periodical><pages>18</pages><volume>1</volume><issue>1</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1038/s41746-018-0029-1</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41746-018-0029-1</url></web-urls></urls><abstract>Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient’s record. We propose a representation of patients’ entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: in-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93–0.94), 30-day unplanned readmission (AUROC 0.75–0.76), prolonged length of stay (AUROC 0.85–0.86), and all of a patient’s final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient’s chart.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Liang, Huiying</author><author>Tsui, Brian Y</author><author>Ni, Hao</author><author>Valentim, Carolina C S</author><author>Baxter, Sally L</author><author>Liu, Guangjian</author><author>Cai, Wenjia</author><author>Kermany, Daniel S</author><author>Sun, Xin</author><author>Chen, Jiancong</author><author>He, Liya</author><author>Zhu, Jie</author><author>Tian, Pin</author><author>Shao, Hua</author><author>Zheng, Lianghong</author><author>Hou, Rui</author><author>Hewett, Sierra</author><author>Li, Gen</author><author>Liang, Ping</author><author>Zang, Xuan</author><author>Zhang, Zhiqi</author><author>Pan, Liyan</author><author>Cai, Huimin</author><author>Ling, Rujuan</author><author>Li, Shuhua</author><author>Cui, Yongwang</author><author>Tang, Shusheng</author><author>Ye, Hong</author><author>Huang, Xiaoyan</author><author>He, Waner</author><author>Liang, Wenqing</author><author>Zhang, Qing</author><author>Jiang, Jianmin</author><author>Yu, Wei</author><author>Gao, Jianqun</author><author>Ou, Wanxing</author><author>Deng, Yingmin</author><author>Hou, Qiaozhen</author><author>Wang, Bei</author><author>Yao, Cuichan</author><author>Liang, Yan</author><author>Zhang, Shu</author><author>Duan, Yaou</author><author>Zhang, Runze</author><author>Gibson, Sarah</author><author>Zhang, Charlotte L</author><author>Li, Oulan</author><author>Zhang, Edward D</author><author>Karin, Gabriel</author><author>Nguyen, Nathan</author><author>Wu, Xiaokang</author><author>Wen, Cindy</author><author>Xu, Jie</author><author>Xu, Wenqin</author><author>Wang, Bochu</author><author>Wang, Winston</author><author>Li, Jing</author><author>Pizzato, Bianca</author><author>Bao, Caroline</author><author>Xiang, Daoman</author><author>He, Wanting</author><author>He, Suiqin</author><author>Zhou, Yugui</author><author>Haw, Weldon</author><author>Goldbaum, Michael</author><author>Tremoulet, Adriana</author><author>Hsu, Chun-Nan</author><author>Carter, Hannah</author><author>Zhu, Long</author><author>Zhang, Kang</author><author>Xia, Huimin</author></authors></contributors><titles><title>Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence</title><secondary-title>Nature Medicine</secondary-title></titles><periodical><full-title>Nature Medicine</full-title></periodical><pages>433-438</pages><volume>25</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s41591-018-0335-9</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41591-018-0335-9</url></web-urls></urls><abstract>Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Chen, Yang-En</author><author>Tang, Kai-Fu</author><author>Peng, Yu-Shao</author><author>Chang, Edward Y.</author></authors></contributors><titles><title>Effective Medical Test Suggestions Using Deep Reinforcement Learning</title><secondary-title>arXiv preprint arXiv:1905.12916</secondary-title></titles><periodical><full-title>arXiv preprint arXiv:1905.12916</full-title></periodical><keywords/><dates><year>2019</year></dates><urls><web-urls><url>http://arxiv.org/abs/1905.12916</url></web-urls></urls><abstract>Effective medical test suggestions benefit both patients and physicians to conserve time and improve diagnosis accuracy. In this work, we show that an agent can learn to suggest effective medical tests. We formulate the problem as a stage-wise Markov decision process and propose a reinforcement learning method to train the agent. We introduce a new representation of multiple action policy along with the training method of the proposed representation. Furthermore, a new exploration scheme is proposed to accelerate the learning of disease distributions. Our experimental results demonstrate that the accuracy of disease diagnosis can be significantly improved with good medical test suggestions.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ismail Fawaz, Hassan</author><author>Forestier, Germain</author><author>Weber, Jonathan</author><author>Idoumghar, Lhassane</author><author>Muller, Pierre-Alain</author></authors></contributors><titles><title>Deep learning for time series classification: a review</title><secondary-title>Data Mining and Knowledge Discovery</secondary-title></titles><periodical><full-title>Data Mining and Knowledge Discovery</full-title></periodical><pages>917-963</pages><volume>33</volume><issue>4</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1007/s10618-019-00619-1</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1007/s10618-019-00619-1</url></web-urls></urls><abstract>Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Lyu, Xinrui</author><author>Hueser, Matthias</author><author>Hyland, Stephanie L.</author><author>Zerveas, George</author><author>Raetsch, Gunnar</author></authors></contributors><titles><title>Improving Clinical Predictions through Unsupervised Time Series Representation Learning</title><secondary-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</secondary-title></titles><periodical><full-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</full-title></periodical><pages>1-8</pages><keywords/><dates><year>2018</year></dates><urls/><abstract>In this work, we investigate unsupervised representation learning on medical time series, which bears the promise of leveraging copious amounts of existing unlabeled data in order to eventually assist clinical decision making. By evaluating on the prediction of clinically relevant outcomes, we show that in a practical setting, unsupervised representation learning can offer clear performance benefits over end-to-end supervised architectures. We experiment with using sequence-to-sequence (Seq2Seq) models in two different ways, as an autoencoder and as a forecaster, and show that the best performance is achieved by a forecasting Seq2Seq model with an integrated attention mechanism, proposed here for the first time in the setting of unsupervised learning for medical time series.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Denaxas, Spiros</author><author>Stenetorp, Pontus</author><author>Riedel, Sebastian</author><author>Pikoula, Maria</author><author>Dobson, Richard</author><author>Hemingway, Harry</author></authors></contributors><titles><title>Application of Clinical Concept Embeddings for Heart Failure Prediction in UK EHR data</title><secondary-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</secondary-title></titles><periodical><full-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</full-title></periodical><pages>1-7</pages><keywords/><dates><year>2018</year></dates><urls/><abstract>Electronic health records (EHR) are increasingly being used for constructing disease risk prediction models. Feature engineering in EHR data however is challenging due to their highly dimensional and heterogeneous nature. Low-dimensional representations of EHR data can potentially mitigate these challenges. In this paper, we use global vectors (GloVe) to learn word embeddings for diagnoses and procedures recorded using 13 million ontology terms across 2.7 million hospitalisations in national UK EHR. We demonstrate the utility of these embeddings by evaluating their performance in identifying patients which are at higher risk of being hospitalised for congestive heart failure. Our findings indicate that embeddings can enable the creation of robust EHR-derived disease risk prediction models and address some the limitations associated with manual clinical feature engineering.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Tomašev, Nenad</author><author>Glorot, Xavier</author><author>Rae, Jack W</author><author>Zielinski, Michal</author><author>Askham, Harry</author><author>Saraiva, Andre</author><author>Mottram, Anne</author><author>Meyer, Clemens</author><author>Ravuri, Suman</author><author>Protsyuk, Ivan</author><author>Connell, Alistair</author><author>Hughes, Cían O</author><author>Karthikesalingam, Alan</author><author>Cornebise, Julien</author><author>Montgomery, Hugh</author><author>Rees, Geraint</author><author>Laing, Chris</author><author>Baker, Clifton R</author><author>Peterson, Kelly</author><author>Reeves, Ruth</author><author>Hassabis, Demis</author><author>King, Dominic</author><author>Suleyman, Mustafa</author><author>Back, Trevor</author><author>Nielson, Christopher</author><author>Ledsam, Joseph R</author><author>Mohamed, Shakir</author></authors></contributors><titles><title>A clinically applicable approach to continuous prediction of future acute kidney injury</title><secondary-title>Nature</secondary-title></titles><periodical><full-title>Nature</full-title></periodical><pages>116-119</pages><volume>572</volume><issue>7767</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s41586-019-1390-1</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41586-019-1390-1</url></web-urls></urls><abstract>The early prediction of deterioration could have an important role in supporting healthcare professionals, as an estimated 11% of deaths in hospital follow a failure to promptly recognize and treat deteriorating patients1. To achieve this goal requires predictions of patient risk that are continuously updated and accurate, and delivered at an individual level with sufficient context and enough time to act. Here we develop a deep learning approach for the continuous risk prediction of future deterioration in patients, building on recent work that models adverse events from electronic health records2–17 and using acute kidney injury—a common and potentially life-threatening condition18—as an exemplar. Our model was developed on a large, longitudinal dataset of electronic health records that cover diverse clinical environments, comprising 703,782 adult patients across 172 inpatient and 1,062 outpatient sites. Our model predicts 55.8% of all inpatient episodes of acute kidney injury, and 90.2% of all acute kidney injuries that required subsequent administration of dialysis, with a lead time of up to 48 h and a ratio of 2 false alerts for every true alert. In addition to predicting future acute kidney injury, our model provides confidence assessments and a list of the clinical features that are most salient to each prediction, alongside predicted future trajectories for clinically relevant blood tests9. Although the recognition and prompt treatment of acute kidney injury is known to be challenging, our approach may offer opportunities for identifying patients at risk within a time window that enables early treatment.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Liu, Xiangan</author><author>Xu, Keyang</author><author>Xie, Pengtao</author><author>Xing, Eric</author></authors></contributors><titles><title>Unsupervised Pseudo-Labeling for Extractive Summarization on Electronic Health Records</title><secondary-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</secondary-title></titles><periodical><full-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</full-title></periodical><pages>1-6</pages><keywords/><dates><year>2018</year></dates><urls/><abstract>Extractive summarization is very useful for physicians to better manage and digest Electronic Health Records (EHRs). However, the training of a supervised model requires disease-specific medical background and is thus very expensive. We studied how to utilize the intrinsic correlation between multiple EHRs to generate pseudo-labels and train a supervised model with no external annotation. Experiments on real-patient data validate that our model is effective in summarizing crucial disease-specific information for patients.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Shickel, B</author><author>Tighe, P J</author><author>Bihorac, A</author><author>Rashidi, P</author></authors></contributors><titles><title>Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis</title><secondary-title>IEEE Journal of Biomedical and Health Informatics</secondary-title></titles><periodical><full-title>IEEE Journal of Biomedical and Health Informatics</full-title></periodical><pages>1589-1604</pages><volume>22</volume><issue>5</issue><keywords><keyword>Clinical informatics</keyword><keyword>EHR data</keyword><keyword>Electronic medical records</keyword><keyword>Hospitals</keyword><keyword>Informatics</keyword><keyword>Machine learning</keyword><keyword>Medical diagnostic imaging</keyword><keyword>administrative healthcare tasks</keyword><keyword>clinical informatics applications</keyword><keyword>deep learning</keyword><keyword>deep learning techniques</keyword><keyword>digital information</keyword><keyword>electronic health record analysis</keyword><keyword>electronic health records</keyword><keyword>health care</keyword><keyword>information extraction</keyword><keyword>learning (artificial intelligence)</keyword><keyword>machine learning</keyword><keyword>machine learning community</keyword><keyword>patient information</keyword><keyword>survey</keyword></keywords><dates><year>2018</year></dates><electronic-resource-num>10.1109/JBHI.2017.2767063</electronic-resource-num><urls/><abstract>The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHRs). While primarily designed for archiving patient information and performing administrative healthcare tasks like billing, many researchers have found secondary use of these records for various clinical informatics applications. Over the same period, the machine learning community has seen widespread advances in the field of deep learning. In this review, we survey the current research on applying deep learning to clinical tasks based on EHR data, where we find a variety of deep learning techniques and frameworks being applied to several types of clinical applications including information extraction, representation learning, outcome prediction, phenotyping, and deidentification. We identify several limitations of current research involving topics such as model interpretability, data heterogeneity, and lack of universal benchmarks. We conclude by summarizing the state of the field and identifying avenues of future deep EHR research.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Wang, Yanshan</author><author>Wang, Liwei</author><author>Rastegar-Mojarad, Majid</author><author>Moon, Sungrim</author><author>Shen, Feichen</author><author>Afzal, Naveed</author><author>Liu, Sijia</author><author>Zeng, Yuqun</author><author>Mehrabi, Saeed</author><author>Sohn, Sunghwan</author><author>Liu, Hongfang</author></authors></contributors><titles><title>Clinical information extraction applications: A literature review</title><secondary-title>Journal of Biomedical Informatics</secondary-title></titles><periodical><full-title>Journal of Biomedical Informatics</full-title></periodical><pages>34-49</pages><volume>77</volume><keywords><keyword>Application</keyword><keyword>Clinical notes</keyword><keyword>Electronic health records</keyword><keyword>Information extraction</keyword><keyword>Natural language processing</keyword></keywords><dates><year>2018</year></dates><electronic-resource-num>https://doi.org/10.1016/j.jbi.2017.11.011</electronic-resource-num><urls><web-urls><url>http://www.sciencedirect.com/science/article/pii/S1532046417302563</url></web-urls></urls><abstract>Background With the rapid adoption of electronic health records (EHRs), it is desirable to harvest information and knowledge from EHRs to support automated systems at the point of care and to enable secondary use of EHRs for clinical and translational research. One critical component used to facilitate the secondary use of EHR data is the information extraction (IE) task, which automatically extracts and encodes clinical information from text. Objectives In this literature review, we present a review of recent published research on clinical information extraction (IE) applications. Methods A literature search was conducted for articles published from January 2009 to September 2016 based on Ovid MEDLINE In-Process &amp; Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and ACM Digital Library. Results A total of 1917 publications were identified for title and abstract screening. Of these publications, 263 articles were selected and discussed in this review in terms of publication venues and data sources, clinical IE tools, methods, and applications in the areas of disease- and drug-related studies, and clinical workflow optimizations. Conclusions Clinical IE has been used for a wide range of applications, however, there is a considerable gap between clinical studies using EHR data and studies using clinical IE. This study enabled us to gain a more concrete understanding of the gap and to provide potential solutions to bridge this gap.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Li, C</author><author>He, B</author><author>Sun, L</author><author>Sun, Y</author></authors></contributors><titles><title>Neural Precision Medicine by Mining Implicit Treatment Concepts</title><secondary-title>2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</secondary-title></titles><periodical><full-title>2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</full-title></periodical><pages>893-898</pages><keywords><keyword>Cancer</keyword><keyword>Dictionaries</keyword><keyword>Genetics</keyword><keyword>K-NRM</keyword><keyword>Kernel</keyword><keyword>Medical diagnostic imaging</keyword><keyword>PM approaches</keyword><keyword>TREC</keyword><keyword>Tumors</keyword><keyword>biomedical articles</keyword><keyword>data mining</keyword><keyword>diseases</keyword><keyword>genetic variants</keyword><keyword>genetics</keyword><keyword>information retrieval task</keyword><keyword>medical concepts</keyword><keyword>medical information systems</keyword><keyword>mining treatment concepts</keyword><keyword>neural IR framework</keyword><keyword>neural nets</keyword><keyword>neural network framework</keyword><keyword>neural precision medicine</keyword><keyword>neural retrieval model</keyword><keyword>oncogene</keyword><keyword>patient record</keyword><keyword>patient treatment</keyword><keyword>query processing</keyword><keyword>standard text retrieval conference</keyword><keyword>text analysis</keyword><keyword>treatment information</keyword><keyword>tumor</keyword></keywords><dates><year>2018</year></dates><isbn>VO  -</isbn><electronic-resource-num>10.1109/BIBM.2018.8621536</electronic-resource-num><urls/><abstract>Precision Medicine (PM) is regarded as an information retrieval (IR) task, in which biomedical articles containing treatment information about specific diseases or genetic variants are retrieved in response to patient record, aiming at providing medical evidence to the point-of-care. In existing PM approaches, manual keywords such as “treatment” and “therapy” are considered direct indicators of treatment information, and are thereby introduced to expand the original query. However, the common medical concepts that are implicitly related to treatment (such as “oncogene”, “tumor”), and differ the relevant documents from the non-relevant ones, are yet to be utilized. To bridge the gap, in this paper, we propose an extension of the state-of-the-art K-NRM neural retrieval model, coined K-NRMPM, to encapsulate the PM solutions within a neural network framework. Specifically, the proposed approach mines a global list of common medical concepts from documents that are judged pertinent to different queries. Thereafter, the mined implicit concepts are incorporated within a neural IR framework to enhance the effectiveness of precision medicine. Experimental results on the standard Text REtrieval Conference (TREC) PM track benchmark confirm the superior performance of the proposed K-NRMPM model.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Tseng, Huan-Hsin</author><author>Luo, Yi</author><author>Cui, Sunan</author><author>Chien, Jen-Tzung</author><author>Ten Haken, Randall K</author><author>Naqa, Issam El</author></authors></contributors><titles><title>Deep reinforcement learning for automated radiation adaptation in lung cancer</title><secondary-title>Medical Physics</secondary-title></titles><periodical><full-title>Medical Physics</full-title></periodical><pages>6690-6705</pages><volume>44</volume><issue>12</issue><keywords><keyword>adaptive radiotherapy</keyword><keyword>deep learning</keyword><keyword>lung cancer</keyword><keyword>reinforcement learning</keyword></keywords><dates><year>2017</year></dates><publisher>John Wiley &amp; Sons, Ltd</publisher><electronic-resource-num>10.1002/mp.12625</electronic-resource-num><notes>doi: 10.1002/mp.12625</notes><research-notes>doi: 10.1002/mp.12625</research-notes><urls><web-urls><url>https://doi.org/10.1002/mp.12625</url></web-urls></urls><abstract>Purpose To investigate deep reinforcement learning (DRL) based on historical treatment plans for developing automated radiation adaptation protocols for nonsmall cell lung cancer (NSCLC) patients that aim to maximize tumor local control at reduced rates of radiation pneumonitis grade 2 (RP2). Methods In a retrospective population of 114 NSCLC patients who received radiotherapy, a three-component neural networks framework was developed for deep reinforcement learning (DRL) of dose fractionation adaptation. Large-scale patient characteristics included clinical, genetic, and imaging radiomics features in addition to tumor and lung dosimetric variables. First, a generative adversarial network (GAN) was employed to learn patient population characteristics necessary for DRL training from a relatively limited sample size. Second, a radiotherapy artificial environment (RAE) was reconstructed by a deep neural network (DNN) utilizing both original and synthetic data (by GAN) to estimate the transition probabilities for adaptation of personalized radiotherapy patients? treatment courses. Third, a deep Q-network (DQN) was applied to the RAE for choosing the optimal dose in a response-adapted treatment setting. This multicomponent reinforcement learning approach was benchmarked against real clinical decisions that were applied in an adaptive dose escalation clinical protocol. In which, 34 patients were treated based on avid PET signal in the tumor and constrained by a 17.2% normal tissue complication probability (NTCP) limit for RP2. The uncomplicated cure probability (P+) was used as a baseline reward function in the DRL. Results Taking our adaptive dose escalation protocol as a blueprint for the proposed DRL (GAN + RAE + DQN) architecture, we obtained an automated dose adaptation estimate for use at ?2/3 of the way into the radiotherapy treatment course. By letting the DQN component freely control the estimated adaptive dose per fraction (ranging from 1?5 Gy), the DRL automatically favored dose escalation/de-escalation between 1.5 and 3.8 Gy, a range similar to that used in the clinical protocol. The same DQN yielded two patterns of dose escalation for the 34 test patients, but with different reward variants. First, using the baseline P+ reward function, individual adaptive fraction doses of the DQN had similar tendencies to the clinical data with an RMSE = 0.76 Gy; but adaptations suggested by the DQN were generally lower in magnitude (less aggressive). Second, by adjusting the P+ reward function with higher emphasis on mitigating local failure, better matching of doses between the DQN and the clinical protocol was achieved with an RMSE = 0.5 Gy. Moreover, the decisions selected by the DQN seemed to have better concordance with patients eventual outcomes. In comparison, the traditional temporal difference (TD) algorithm for reinforcement learning yielded an RMSE = 3.3 Gy due to numerical instabilities and lack of sufficient learning. Conclusion We demonstrated that automated dose adaptation by DRL is a feasible and a promising approach for achieving similar results to those chosen by clinicians. The process may require customization of the reward function if individual cases were to be considered. However, development of this framework into a fully credible autonomous system for clinical decision support would require further validation on larger multi-institutional datasets.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Meyer, Alexander</author><author>Zverinski, Dina</author><author>Pfahringer, Boris</author><author>Kempfert, Jörg</author><author>Kuehne, Titus</author><author>Sündermann, Simon H</author><author>Stamm, Christof</author><author>Hofmann, Thomas</author><author>Falk, Volkmar</author><author>Eickhoff, Carsten</author></authors></contributors><titles><title>Machine learning for real-time prediction of complications in critical care: a retrospective study</title><secondary-title>The Lancet Respiratory Medicine</secondary-title></titles><periodical><full-title>The Lancet Respiratory Medicine</full-title></periodical><pages>905-914</pages><volume>6</volume><issue>12</issue><keywords/><dates><year>2018</year></dates><publisher>Elsevier</publisher><electronic-resource-num>10.1016/S2213-2600(18)30300-X</electronic-resource-num><notes>doi: 10.1016/S2213-2600(18)30300-X</notes><research-notes>doi: 10.1016/S2213-2600(18)30300-X</research-notes><urls><web-urls><url>https://doi.org/10.1016/S2213-2600(18)30300-X</url></web-urls></urls><abstract>BackgroundThe large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Suresh, Harini</author><author>Hunt, Nathan</author><author>Johnson, Alistair</author><author>Celi, Leo Anthony</author><author>Szolovits, Peter</author><author>Ghassemi, Marzyeh</author></authors><secondary-authors><author>Doshi-Velez, Finale</author><author>Fackler, Jim</author><author>Kale, David</author><author>Ranganath, Rajesh</author><author>Wallace, Byron</author><author>Wiens, Jenna</author></secondary-authors></contributors><titles><title>Clinical Intervention Prediction and Understanding with Deep Neural Networks</title><secondary-title>Proceedings of the 2nd Machine Learning for Healthcare Conference</secondary-title></titles><periodical><full-title>Proceedings of the 2nd Machine Learning for Healthcare Conference</full-title></periodical><pages>322-337</pages><volume>68</volume><keywords/><dates><year>2017</year></dates><pub-location>Boston, Massachusetts</pub-location><publisher>PMLR</publisher><urls><web-urls><url>http://proceedings.mlr.press/v68/suresh17a.html</url></web-urls></urls><abstract>Real-time prediction of clinical interventions remains a challenge within intensive care units (ICUs). This task is complicated by data sources that are sparse, noisy, heterogeneous and outcomes that are imbalanced. In this work, we integrate data across many ICU sources — vitals, labs, notes, demographics — and focus on learning rich representations of this data to predict onset and weaning of multiple invasive interventions. In particular, we compare both long short-term memory networks (LSTM) and convolutional neural networks (CNN) for prediction of five intervention tasks: invasive ventilation, non-invasive ventilation, vasopressors, colloid boluses, and crystalloid boluses. Our predictions are done in a forward-facing manner after a six hour gap time to support clinically actionable planning. We achieve state-of-the-art results on these predictive tasks using deep architectures. Further, we explore the use of feature occlusion to interpret LSTM models, and compare this to the interpretability gained from examining inputs that maximally activate CNN outputs. We show that our models are able to significantly outperform baselines for intervention prediction, and provide insight into model learning.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Bajor, Jacek M.</author><author>Lasko, Thomas A.</author></authors></contributors><titles><title>Predicting Medications from Diagnostic Codes with Recurrent Neural Networks</title><secondary-title>International Conference on Learning Representations (ICLR) 2017</secondary-title></titles><periodical><full-title>International Conference on Learning Representations (ICLR) 2017</full-title></periodical><pages>1-19</pages><keywords/><dates><year>2017</year></dates><urls/><abstract>It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient’s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Janssoone, Thomas</author><author>Bic, Clémence</author><author>Kanoun, Dorra</author><author>Hornus, Pierre</author><author>Rinder, Pierre</author></authors></contributors><titles><title>Machine Learning on Electronic Health Records: Models and Features Usages to predict Medication Non-Adherence</title><secondary-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</secondary-title></titles><periodical><full-title>Proceedings of the Machine Learning for Health (ML4H) Workshop at NeurIPS 2018</full-title></periodical><pages>1-5</pages><keywords/><dates><year>2018</year></dates><urls/><abstract>Adherence can be defined as &quot;the extent to which patients take their medications as prescribed by their healthcare providers&quot;[Osterberg and Blaschke, 2005]. World Health Organization's reports point out that, in developed countries, only about 50% of patients with chronic diseases correctly follow their treatments. This severely compromises the efficiency of long-term therapy and increases the cost of health services. We propose in this paper different models of patient drug consumption in breast cancer treatments. The aim of these different approaches is to predict medication non-adherence while giving insights to doctors of the underlying reasons of these illegitimate drop-outs. Working with oncologists, we show the interest of Machine- Learning algorithms fined tune by the feedback of experts to estimate a risk score of a patient's non-adherence and thus improve support throughout their care path.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Xiao, Cao</author><author>Choi, Edward</author><author>Sun, Jimeng</author></authors></contributors><titles><title>Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review</title><secondary-title>Journal of the American Medical Informatics Association</secondary-title></titles><periodical><full-title>Journal of the American Medical Informatics Association</full-title></periodical><pages>1419-1428</pages><volume>25</volume><issue>10</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1093/jamia/ocy068</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1093/jamia/ocy068</url></web-urls></urls><abstract>To conduct a systematic review of deep learning models for electronic health record (EHR) data, and illustrate various deep learning architectures for analyzing different data sources and their target applications. We also highlight ongoing research and identify open challenges in building deep learning models of EHRs.We searched PubMed and Google Scholar for papers on deep learning studies using EHR data published between January 1, 2010, and January 31, 2018. We summarize them according to these axes: types of analytics tasks, types of deep learning model architectures, special challenges arising from health data and tasks and their potential solutions, as well as evaluation strategies.We surveyed and analyzed multiple aspects of the 98 articles we found and identified the following analytics tasks: disease detection/classification, sequential prediction of clinical events, concept embedding, data augmentation, and EHR data privacy. We then studied how deep architectures were applied to these tasks. We also discussed some special challenges arising from modeling EHR data and reviewed a few popular approaches. Finally, we summarized how performance evaluations were conducted for each task.Despite the early success in using deep learning for health analytics applications, there still exist a number of issues to be addressed. We discuss them in detail including data and label availability, the interpretability and transparency of the model, and ease of deployment.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Che, Zhengping</author><author>Purushotham, Sanjay</author><author>Cho, Kyunghyun</author><author>Sontag, David</author><author>Liu, Yan</author></authors></contributors><titles><title>Recurrent Neural Networks for Multivariate Time Series with Missing Values</title><secondary-title>Scientific Reports</secondary-title></titles><periodical><full-title>Scientific Reports</full-title></periodical><pages>6085</pages><volume>8</volume><issue>1</issue><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1038/s41598-018-24271-9</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41598-018-24271-9</url></web-urls></urls><abstract>Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Gupta, Priyanka</author><author>Malhotra, Pankaj</author><author>Vig, Lovekesh</author><author>Shroff, Gautam</author></authors></contributors><titles><title>Transfer Learning for Clinical Time Series Analysis using Recurrent Neural Networks</title><secondary-title>Machine Learning for Medicine and Healthcare Workshop at ACM KDD 2018 Conference</secondary-title></titles><periodical><full-title>Machine Learning for Medicine and Healthcare Workshop at ACM KDD 2018 Conference</full-title></periodical><pages>1-4</pages><keywords/><dates><year>2018</year></dates><urls/><abstract>Deep neural networks have shown promising results for various clinical prediction tasks such as diagnosis, mortality prediction, predicting duration of stay in hospital, etc. However, training deep networks -- such as those based on Recurrent Neural Networks (RNNs) -- requires large labeled data, high computational resources, and significant hyperparameter tuning effort. In this work, we investigate as to what extent can transfer learning address these issues when using deep RNNs to model multivariate clinical time series. We consider transferring the knowledge captured in an RNN trained on several source tasks simultaneously using a large labeled dataset to build the model for a target task with limited labeled data. An RNN pre-trained on several tasks provides generic features, which are then used to build simpler linear models for new target tasks without training task-specific RNNs. For evaluation, we train a deep RNN to identify several patient phenotypes on time series from MIMIC-III database, and then use the features extracted using that RNN to build classifiers for identifying previously unseen phenotypes, and also for a seemingly unrelated task of in-hospital mortality. We demonstrate that (i) models trained on features extracted using pre-trained RNN outperform or, in the worst case, perform as well as task-specific RNNs; (ii) the models using features from pre-trained models are more robust to the size of labeled data than task-specific RNNs; and (iii) features extracted using pre-trained RNN are generic enough and perform better than typical statistical hand-crafted features.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Futoma, Joseph</author><author>Hariharan, Sanjay</author><author>Heller, Katherine</author><author>Sendak, Mark</author><author>Brajer, Nathan</author><author>Clement, Meredith</author><author>Bedoya, Armando</author><author>O’Brien, Cara</author></authors><secondary-authors><author>Doshi-Velez, Finale</author><author>Fackler, Jim</author><author>Kale, David</author><author>Ranganath, Rajesh</author><author>Wallace, Byron</author><author>Wiens, Jenna</author></secondary-authors></contributors><titles><title>An Improved Multi-Output Gaussian Process RNN with Real-Time Validation for Early Sepsis Detection</title><secondary-title>Proceedings of the 2nd Machine Learning for Healthcare Conference</secondary-title></titles><periodical><full-title>Proceedings of the 2nd Machine Learning for Healthcare Conference</full-title></periodical><pages>243-254</pages><volume>68</volume><keywords/><dates><year>2017</year></dates><pub-location>Boston, Massachusetts</pub-location><publisher>PMLR</publisher><urls><web-urls><url>http://proceedings.mlr.press/v68/futoma17a.html</url></web-urls></urls><abstract>Sepsis is a poorly understood and potentially life-threatening complication that can occur as a result of infection. Early detection and treatmenz improves patient outcomes, and as such it poses an important challenge in medicine. In this work, we develop a flexible classifier that leverages streaming lab results, vitals, and medications to predict sepsis before it occurs. We model patient clinical time series with multi-output Gaussian processes, maintaining uncertainty about the physiological state of a patient while also imputing missing values. The mean function takes into account the effects of medications administered on the trajectories of the physiological variables. Latent function values from the Gaussian process are then fed into a deep recurrent neural network to classify patient encounters as septic or not, and the overall model is trained end-to-end using back-propagation. We train and validate our model on a large dataset of 18 months of heterogeneous inpatient stays from the Duke University Health System, and develop a new “real-time” validation scheme for simulat-ing the performance of our model as it will actually be used. Our proposed method substantially outperforms clinical baselines, and improves on a previous related model for detecting sepsis. Our model’s predictions will be displayed in a real-time analytics dashboard to be used by a sepsis rapid response team to help detect and improve treatment of sepsis.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Passalis, N</author><author>Tsantekidis, A</author><author>Tefas, A</author><author>Kanniainen, J</author><author>Gabbouj, M</author><author>Iosifidis, A</author></authors></contributors><titles><title>Time-series classification using neural Bag-of-Features</title><secondary-title>2017 25th European Signal Processing Conference (EUSIPCO)</secondary-title></titles><periodical><full-title>2017 25th European Signal Processing Conference (EUSIPCO)</full-title></periodical><pages>301-305</pages><keywords><keyword>Bag-of-Features model</keyword><keyword>BoF model</keyword><keyword>Brain modeling</keyword><keyword>Electroencephalography</keyword><keyword>Feature extraction</keyword><keyword>Hidden Markov models</keyword><keyword>Histograms</keyword><keyword>Neurons</keyword><keyword>RBF layer</keyword><keyword>accumulation layer</keyword><keyword>backpropagation</keyword><keyword>classification metrics</keyword><keyword>deep neural networks</keyword><keyword>feature extraction</keyword><keyword>feature transformation layers</keyword><keyword>fully connected layers</keyword><keyword>generalisation (artificial intelligence)</keyword><keyword>learning (artificial intelligence)</keyword><keyword>neural generalization</keyword><keyword>neural layer</keyword><keyword>pattern classification</keyword><keyword>radial basis function networks</keyword><keyword>time series</keyword><keyword>time-series classification</keyword><keyword>time-series datasets</keyword><keyword>time-series representation</keyword></keywords><dates><year>2017</year></dates><isbn>2076-1465 VO  -</isbn><electronic-resource-num>10.23919/EUSIPCO.2017.8081217</electronic-resource-num><urls/><abstract>Classification of time-series data is a challenging problem with many real-world applications, ranging from identifying medical conditions from electroencephalography (EEG) measurements to forecasting the stock market. The well known Bag-of-Features (BoF) model was recently adapted towards time-series representation. In this work, a neural generalization of the BoF model, composed of an RBF layer and an accumulation layer, is proposed as a neural layer that receives the features extracted from a time-series and gradually builds its representation. The proposed method can be combined with any other layer or classifier, such as fully connected layers or feature transformation layers, to form deep neural networks for time-series classification. The resulting networks are end-to-end differentiable and they can be trained using regular back-propagation. It is demonstrated, using two time-series datasets, including a large-scale financial dataset, that the proposed approach can significantly increase the classification metrics over other baseline and state-of-the-art techniques.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Liu, Siqi</author><author>Ngiam, Kee Yuan</author><author>Feng, Mengling</author></authors></contributors><titles><title>Deep Reinforcement Learning for Clinical Decision Support: A Brief Survey</title><secondary-title>arXiv preprint arXiv:1907.09475</secondary-title></titles><periodical><full-title>arXiv preprint arXiv:1907.09475</full-title></periodical><keywords/><dates><year>2019</year></dates><urls><web-urls><url>https://arxiv.org/abs/1907.09475</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Esteva, Andre</author><author>Robicquet, Alexandre</author><author>Ramsundar, Bharath</author><author>Kuleshov, Volodymyr</author><author>DePristo, Mark</author><author>Chou, Katherine</author><author>Cui, Claire</author><author>Corrado, Greg</author><author>Thrun, Sebastian</author><author>Dean, Jeff</author></authors></contributors><titles><title>A guide to deep learning in healthcare</title><secondary-title>Nature Medicine</secondary-title></titles><periodical><full-title>Nature Medicine</full-title></periodical><pages>24-29</pages><volume>25</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s41591-018-0316-z</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41591-018-0316-z</url></web-urls></urls><abstract>Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gottesman, Omer</author><author>Johansson, Fredrik</author><author>Komorowski, Matthieu</author><author>Faisal, Aldo</author><author>Sontag, David</author><author>Doshi-Velez, Finale</author><author>Celi, Leo Anthony</author></authors></contributors><titles><title>Guidelines for reinforcement learning in healthcare</title><secondary-title>Nature Medicine</secondary-title></titles><periodical><full-title>Nature Medicine</full-title></periodical><pages>16-18</pages><volume>25</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s41591-018-0310-5</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41591-018-0310-5</url></web-urls></urls><abstract>In this Comment, we provide guidelines for reinforcement learning for decisions about patient treatment that we hope will accelerate the rate at which observational cohorts can inform healthcare practice in a safe, risk-conscious manner.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Harutyunyan, Hrayr</author><author>Khachatrian, Hrant</author><author>Kale, David C</author><author>Ver Steeg, Greg</author><author>Galstyan, Aram</author></authors></contributors><titles><title>Multitask learning and benchmarking with clinical time series data</title><secondary-title>Scientific Data</secondary-title></titles><periodical><full-title>Scientific Data</full-title></periodical><pages>96</pages><volume>6</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1038/s41597-019-0103-9</electronic-resource-num><urls><web-urls><url>https://doi.org/10.1038/s41597-019-0103-9</url></web-urls></urls><abstract>Health care is one of the most exciting frontiers in data mining and machine learning. Successful adoption of electronic health records (EHRs) created an explosion in digital clinical data available for analysis, but progress in machine learning for healthcare research has been difficult to measure because of the absence of publicly available benchmark data sets. To address this problem, we propose four clinical prediction benchmarks using data derived from the publicly available Medical Information Mart for Intensive Care (MIMIC-III) database. These tasks cover a range of clinical problems including modeling risk of mortality, forecasting length of stay, detecting physiologic decline, and phenotype classification. We propose strong linear and neural baselines for all four tasks and evaluate the effect of deep supervision, multitask training and data-specific architectural modifications on the performance of neural models.</abstract></record></records></xml>
